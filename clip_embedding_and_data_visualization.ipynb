{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "517ce90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4f02f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 9401/9401 [1.2s elapsed, 0s remaining, 7.8K samples/s]         \n",
      "Dataset created with 9401 samples.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 117\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset created with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Generate embeddings using the FiftyOne Zoo model\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m generate_embeddings_with_zoo(dataset)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbeddings generated.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 88\u001b[0m, in \u001b[0;36mgenerate_embeddings_with_zoo\u001b[1;34m(dataset, model_name, batch_size, device, save_path)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Load pre-trained model from FiftyOne Zoo\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m model \u001b[38;5;241m=\u001b[39m foz\u001b[38;5;241m.\u001b[39mload_zoo_model(model_name, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Compute embeddings (this call uses dataset.compute_embeddings under the hood)\u001b[39;00m\n\u001b[0;32m     91\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mcompute_embeddings(\n\u001b[0;32m     92\u001b[0m     model,\n\u001b[0;32m     93\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m     94\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[0;32m     95\u001b[0m )\n",
      "File \u001b[1;32m~\\.conda\\envs\\timmies\\Lib\\site-packages\\fiftyone\\zoo\\models\\__init__.py:308\u001b[0m, in \u001b[0;36mload_zoo_model\u001b[1;34m(name_or_url, model_name, download_if_necessary, ensure_requirements, install_requirements, error_level, cache, **kwargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m     model \u001b[38;5;241m=\u001b[39m _load_remote_model(model\u001b[38;5;241m.\u001b[39mname, model_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 308\u001b[0m     model \u001b[38;5;241m=\u001b[39m fom\u001b[38;5;241m.\u001b[39mload_model(config_dict, model_path\u001b[38;5;241m=\u001b[39mmodel_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    311\u001b[0m     _MODELS[key] \u001b[38;5;241m=\u001b[39m model\n",
      "File \u001b[1;32m~\\.conda\\envs\\timmies\\Lib\\site-packages\\fiftyone\\core\\models.py:1916\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(model_config_dict, model_path, **kwargs)\u001b[0m\n\u001b[0;32m   1910\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1911\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel config must implement the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m interface\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1912\u001b[0m             \u001b[38;5;241m%\u001b[39m etal\u001b[38;5;241m.\u001b[39mHasPublishedModel\n\u001b[0;32m   1913\u001b[0m         )\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;66;03m# Build model\u001b[39;00m\n\u001b[1;32m-> 1916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m config\u001b[38;5;241m.\u001b[39mbuild()\n",
      "File \u001b[1;32m~\\.conda\\envs\\timmies\\Lib\\site-packages\\eta\\core\\learning.py:296\u001b[0m, in \u001b[0;36mModelConfig.build\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    290\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Factory method that builds the Model instance from the config\u001b[39;00m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    specified by this class.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \n\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m        a Model instance\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_cls(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n",
      "File \u001b[1;32m~\\.conda\\envs\\timmies\\Lib\\site-packages\\fiftyone\\utils\\clip\\zoo.py:82\u001b[0m, in \u001b[0;36mTorchCLIPModel.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config):\n\u001b[1;32m---> 82\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer \u001b[38;5;241m=\u001b[39m SimpleTokenizer(config\u001b[38;5;241m.\u001b[39mtokenizer_path)\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\timmies\\Lib\\site-packages\\fiftyone\\utils\\torch.py:538\u001b[0m, in \u001b[0;36mTorchImageModel.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_model(config)\n\u001b[1;32m--> 538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_model(config)\n\u001b[0;32m    540\u001b[0m \u001b[38;5;66;03m# Build transforms\u001b[39;00m\n\u001b[0;32m    541\u001b[0m transforms, ragged_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_transforms(config)\n",
      "File \u001b[1;32m~\\.conda\\envs\\timmies\\Lib\\site-packages\\fiftyone\\utils\\clip\\zoo.py:119\u001b[0m, in \u001b[0;36mTorchCLIPModel._load_model\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, config):\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(config\u001b[38;5;241m.\u001b[39mmodel_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 119\u001b[0m         model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(f, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m build_model(model\u001b[38;5;241m.\u001b[39mstate_dict())\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[1;32m~\\.conda\\envs\\timmies\\Lib\\site-packages\\torch\\jit\\_serialization.py:165\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, _extra_files, _restore_shapes)\u001b[0m\n\u001b[0;32m    163\u001b[0m     cpp_module \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mimport_ir_module(cu, os\u001b[38;5;241m.\u001b[39mfspath(f), map_location, _extra_files, _restore_shapes)  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 165\u001b[0m     cpp_module \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mimport_ir_module_from_buffer(\n\u001b[0;32m    166\u001b[0m         cu, f\u001b[38;5;241m.\u001b[39mread(), map_location, _extra_files, _restore_shapes\n\u001b[0;32m    167\u001b[0m     )  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m# TODO: Pretty sure this approach loses ConstSequential status and such\u001b[39;00m\n\u001b[0;32m    170\u001b[0m ret \u001b[38;5;241m=\u001b[39m wrap_cpp_module(cpp_module)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.brain as fob\n",
    "import fiftyone.zoo as foz\n",
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from PIL import Image\n",
    "\n",
    "def create_fiftyone_dataset_with_labels(image_directories):\n",
    "    if \"cups\" in fo.list_datasets():\n",
    "        fo.delete_dataset(\"cups\")\n",
    "    dataset = fo.Dataset(\"cups\")\n",
    "    \n",
    "    samples = []\n",
    "    for image_dir in image_directories:\n",
    "        # Use the folder name as a temporary label\n",
    "        label = os.path.basename(os.path.normpath(image_dir))\n",
    "        image_paths = [\n",
    "            os.path.join(image_dir, f)\n",
    "            for f in os.listdir(image_dir)\n",
    "            if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "        ]\n",
    "        for image_path in image_paths:\n",
    "            # Option 1: Add a simple field\n",
    "            sample = fo.Sample(filepath=image_path, temp_label=label)\n",
    "            # Option 2: Use a FiftyOne Classification field:\n",
    "            # sample[\"ground_truth\"] = fo.Classification(label=label)\n",
    "            samples.append(sample)\n",
    "    dataset.add_samples(samples)\n",
    "    return dataset\n",
    "\n",
    "def create_fiftyone_dataset(image_directories):\n",
    "    \"\"\"\n",
    "    Creates a FiftyOne dataset from images in multiple directories.\n",
    "\n",
    "    Args:\n",
    "        image_directories: A list of paths to the directories containing the images.\n",
    "\n",
    "    Returns:\n",
    "        A fiftyone.core.dataset.Dataset object.\n",
    "    \"\"\"\n",
    "\n",
    "    #dataset = fo.Dataset(\"timmies\")\n",
    "    if \"cups\" in fo.list_datasets():\n",
    "        fo.delete_dataset(\"cups\")\n",
    "    dataset = fo.Dataset(\"cups\")\n",
    "    \n",
    "    samples = []\n",
    "    for image_dir in image_directories:  # Iterate through the list of directories\n",
    "        try:\n",
    "            image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            for image_path in image_paths:\n",
    "                sample = fo.Sample(filepath=image_path)\n",
    "                samples.append(sample)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: Directory not found: {image_dir}\")\n",
    "        except NotADirectoryError:\n",
    "            print(f\"Warning: Not a directory: {image_dir}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error processing directory {image_dir}: {e}\")\n",
    "\n",
    "\n",
    "    dataset.add_samples(samples)\n",
    "    return dataset\n",
    "\n",
    "def generate_embeddings_with_zoo(\n",
    "    dataset,\n",
    "    #model_name=\"resnet50-imagenet-torch\",\n",
    "    #model_name=\"mobilenet-v2-imagenet-torch\", \n",
    "    model_name = \"clip-vit-base32-torch\",\n",
    "    batch_size=24,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    #save_path=\"resnet50_embeddings.pth\",\n",
    "    #save_path=\"mobilenet_embeddings.pth\"\n",
    "    save_path=\"clip_embeddings_victor.pth\"\n",
    "\n",
    "):\n",
    "    # If embeddings have already been computed, load and return them\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"Loading saved embeddings from {save_path}\")\n",
    "        embeddings = torch.load(save_path, weights_only = False)\n",
    "        #embeddings = torch.load(save_path, map_location=device)\n",
    "        return embeddings\n",
    "\n",
    "    # Load pre-trained model from FiftyOne Zoo\n",
    "    model = foz.load_zoo_model(model_name, device=device)\n",
    "    \n",
    "    # Compute embeddings (this call uses dataset.compute_embeddings under the hood)\n",
    "    embeddings = dataset.compute_embeddings(\n",
    "        model,\n",
    "        batch_size=batch_size,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Save embeddings for future reuse\n",
    "    torch.save(embeddings, save_path)\n",
    "    print(f\"Embeddings saved to {save_path}\")\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your directory\n",
    "    # image_directory = \"/Users/yujieming/syde770_cups/all_in_one_v1\"\n",
    "    # image_directory = \"/Users/yujieming/syde770_cups/jieming_images_v2 （crop）/all_cropped\"\n",
    "    image_directories = [\n",
    "        \"C:/Users/vsung/OneDrive - University of Waterloo/SYDE750/projectDVCStorage/tims\",  # Replace with your directory\n",
    "        \"C:/Users/vsung/OneDrive - University of Waterloo/SYDE750/projectDVCStorage/not_tims\", # add the second image directory here\n",
    "        # Add more directories as needed\n",
    "    ]\n",
    "\n",
    "    dataset = create_fiftyone_dataset_with_labels(image_directories)\n",
    "    print(f\"Dataset created with {len(dataset)} samples.\")\n",
    "\n",
    "    # Generate embeddings using the FiftyOne Zoo model\n",
    "    embeddings = generate_embeddings_with_zoo(dataset)\n",
    "    print(\"Embeddings generated.\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "raw",
   "id": "78a62064",
   "metadata": {},
   "source": [
    " # Compute visualization\n",
    "    results = fob.compute_visualization(\n",
    "        dataset, embeddings=embeddings, method = \"umap\", seed=51, brain_key=\"img_viz\"\n",
    "    )\n",
    "    print(\"Visualization computed.\")\n",
    "\n",
    "    session = fo.launch_app(dataset) # Launch the app after visualization\n",
    "    print(\"FiftyOne App launched.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb58d929-c3f9-4082-abcf-d66d9eca2b81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
